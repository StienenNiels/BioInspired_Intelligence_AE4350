{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv, VecMonitor, VecNormalize\n",
    "from stable_baselines3.common.vec_env.base_vec_env import VecEnv, VecEnvStepReturn, VecEnvWrapper\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1857305660, 1857305661, 1857305662, 1857305663, 1857305664, 1857305665, 1857305666, 1857305667, 1857305668, 1857305669, 1857305670, 1857305671, 1857305672, 1857305673, 1857305674, 1857305675]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bbf2653e114ecbb39049231e9a2d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class VecPendulumRewardWrapper(VecEnvWrapper):\n",
    "    def __init__(self, venv: VecEnv):\n",
    "        super().__init__(venv=venv)\n",
    "\n",
    "    def reset(self) -> np.ndarray:\n",
    "        obs = self.venv.reset()\n",
    "        return obs\n",
    "    \n",
    "    def step_async(self, actions: np.ndarray) -> None:\n",
    "        self.venv.step_async(actions)\n",
    "\n",
    "    def step_wait(self) -> VecEnvStepReturn:\n",
    "        obs, reward, done, info = self.venv.step_wait()\n",
    "        reward = 1- obs[:, 0]**2 - obs[:, 1]**2\n",
    "        return obs, reward, done, info\n",
    "\n",
    "def make_env(env_id, rank, seed=0):\n",
    "    def _init():\n",
    "        env = gym.make(env_id)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "env_id = 'InvertedPendulum-v4'  # Replace with your MuJoCo environment\n",
    "num_envs = 16  # Number of parallel environments\n",
    "\n",
    "# Create the vectorized environment\n",
    "env = SubprocVecEnv([make_env(env_id, i) for i in range(num_envs)])\n",
    "print(env.seed())\n",
    "# Add the reward wrapper\n",
    "env = VecPendulumRewardWrapper(env)\n",
    "env = VecMonitor(env)  # Optional: for monitoring and logging\n",
    "\n",
    "model = SAC('MlpPolicy', env, learning_rate=0.0003, buffer_size=1e6, learning_starts=100, batch_size=256, tau=0.005, gamma=0.99, verbose=0)\n",
    "model.learn(total_timesteps=1e5, log_interval=4, progress_bar=True)\n",
    "model.save(\"sac_pendulum\")\n",
    "\n",
    "# del model # remove to demonstrate saving and loading\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAC.load(\"sac_pendulum\")\n",
    "\n",
    "class PendulumRewardWrapper(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env=env)\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        reward = 1 - obs[0]**2 - obs[1]**2\n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "env = gym.make(\"InvertedPendulum-v4\", render_mode='rgb_array')\n",
    "env = PendulumRewardWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, info = env.reset()\n",
    "data = []\n",
    "total_reward = 0\n",
    "terminated = False\n",
    "truncated = False\n",
    "while not truncated:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    data.append(np.concatenate((action, obs, np.array([reward]), np.array([total_reward]))))\n",
    "\n",
    "names = [\"action\", \"cart_pos\", \"pole_angle\", \"cart_velocity\", \"pole_ang_vel\", \"reward\", \"total_reward\"]\n",
    "\n",
    "P = pd.DataFrame(data, columns = names)\n",
    "\n",
    "name = \"testrun\"\n",
    "saveFile = \"recordings/\" + name\n",
    "P.to_csv(saveFile + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\niels\\anaconda3\\envs\\BII_par\\Lib\\site-packages\\gymnasium\\wrappers\\record_video.py:94: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\niels\\Desktop\\BioInspired Intelligence\\BII_project\\BioInspired_Intelligence_AE4350\\save_videos1 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.wrappers.RecordVideo(env, video_folder=\"./save_videos1\", disable_logger=True)\n",
    "obs, info = env.reset()\n",
    "terminated, truncated = False, False\n",
    "while not (terminated or truncated):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BII_mujoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
